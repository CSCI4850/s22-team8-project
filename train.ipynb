{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00004372-c1cc-47d2-a169-46f5d0f09b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from Generator import Generator\n",
    "from Normalizer import Normalizer\n",
    "from RealData import RealData\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f1de659-6e81-40d6-8eb1-a650cfd5cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d6cb645-4bbb-47a9-bf10-35b13e560e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, recipe_normalizer, quant_normalizer, accs):\n",
    "    model.save(f\"./models/{run}_rank_{rank}/{run}_rank_{rank}.h5\")\n",
    "    \n",
    "    np.savetxt(f\"./models/{run}_rank_{rank}/norm_recipe_max\", recipe_normalizer.feature_max)\n",
    "    np.savetxt(f\"./models/{run}_rank_{rank}/norm_recipe_min\", recipe_normalizer.feature_min)\n",
    "    \n",
    "    np.savetxt(f\"./models/{run}_rank_{rank}/norm_quant_max\", quant_normalizer.feature_max)\n",
    "    np.savetxt(f\"./models/{run}_rank_{rank}/norm_quant_min\", quant_normalizer.feature_min)\n",
    "    \n",
    "    \n",
    "    # open file for writing, \"w\" is writing\n",
    "    w = csv.writer(open(f\"./models/{run}_rank_{rank}/accuracy.csv\", \"w\"))\n",
    "\n",
    "    # loop over dictionary keys and values\n",
    "    for key, val in accs.items():\n",
    "\n",
    "        # write every key and value to file\n",
    "        w.writerow([key, val])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac47287-209f-4008-8454-e56dd05ae727",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c0e4d0-4efc-4644-8660-187b6b2bbd89",
   "metadata": {},
   "source": [
    "#### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30121acf-492e-499d-9290-75f567ff39b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = True\n",
    "normalize = True\n",
    "\n",
    "train_examples = 100000\n",
    "test_examples = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f336abc6-2b96-4e0b-858f-f32a51d32933",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "105f9c8b-e112-4cdc-a24a-12535671b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 1024                          \n",
    "stack = 6                                    \n",
    "\n",
    "optimizer = keras.optimizers.Nadam()        \n",
    "loss = keras.losses.MSE\n",
    "\n",
    "\n",
    "metrics = keras.metrics.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a5bf93-f5c9-4772-9ee8-d1675dca741f",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74636d58-d1d8-412c-b393-d0c2d27c103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 1000\n",
    "\n",
    "validation_split = 0.2\n",
    "verbose = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452ebb1-97e9-4f34-a429-3ab296001e1b",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23032494-9688-4711-9ebe-1d05222b3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator('nutrients.csv') # filename with data\n",
    "generator.generate(train_examples) # generates arg number of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c8e6f0e-363c-4c6a-a90b-857b0d00e820",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank:\n",
    "    generator.rank()\n",
    "    \n",
    "recipes = generator.recipes\n",
    "quant = generator.quant\n",
    "    \n",
    "if normalize:\n",
    "    recipe_normalizer = Normalizer()\n",
    "    recipe_normalizer.fit(recipes)\n",
    "    recipes = recipe_normalizer.normalize(recipes)\n",
    "    \n",
    "    quant_normalizer = Normalizer()\n",
    "    quant_normalizer.fit(quant)\n",
    "    quant = quant_normalizer.normalize(quant)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a35f454-3e29-4a71-9cb7-298f97058578",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88feb92b-5433-4b83-a6f3-d8dbc1b1a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = embed_dim\n",
    "stack = stack\n",
    "i1 = keras.layers.Input(generator.recipes.shape[1:])\n",
    "f1 = keras.layers.Flatten()(i1)\n",
    "y1 = keras.layers.Dense(embed_dim)(f1)\n",
    "\n",
    "# Stack residual blocks (skip connections)\n",
    "for i in range(stack):\n",
    "    y2 = y1\n",
    "    y1 = keras.layers.Dense(embed_dim,\n",
    "        activation=keras.activations.relu)(y1)\n",
    "    y1 = keras.layers.Dropout(0.35)(y1)\n",
    "    y1 = keras.layers.Add()([y1,y2])\n",
    "    y1 = keras.layers.LayerNormalization()(y1)\n",
    "    \n",
    "        \n",
    "\n",
    "if normalize:\n",
    "    o1 = keras.layers.Dense(quant.shape[1],activation=keras.activations.softplus)(y1)\n",
    "    \n",
    "else:\n",
    "    o1 = keras.layers.Dense(quant.shape[1])(y1)\n",
    "    \n",
    "model = keras.Model(i1,o1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "270046ea-1e0b-48ac-bd20-8f65d92f4284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(model,to_file='recipe_model.png',show_shapes=True,expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "756ff5a2-df36-48cb-b77b-1f9b58ec4351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 28)]         0           []                               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 28)           0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1024)         29696       ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1024)         1049600     ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 1024)         0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 1024)         0           ['dropout_6[0][0]',              \n",
      "                                                                  'dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 1024)        2048        ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1024)         1049600     ['layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 1024)         0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 1024)         0           ['dropout_7[0][0]',              \n",
      "                                                                  'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 1024)        2048        ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1024)         1049600     ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 1024)         0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 1024)         0           ['dropout_8[0][0]',              \n",
      "                                                                  'layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 1024)        2048        ['add_8[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 1024)         1049600     ['layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 1024)         0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 1024)         0           ['dropout_9[0][0]',              \n",
      "                                                                  'layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 1024)        2048        ['add_9[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1024)         1049600     ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 1024)         0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 1024)         0           ['dropout_10[0][0]',             \n",
      "                                                                  'layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 1024)        2048        ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 1024)         1049600     ['layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 1024)         0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 1024)         0           ['dropout_11[0][0]',             \n",
      "                                                                  'layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 1024)        2048        ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 15)           15375       ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,354,959\n",
      "Trainable params: 6,354,959\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "720ec192-b5a7-411e-8c6c-743b5ae34542",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5e032fb-d1c2-44e3-beb7-af9c61eafaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f\"./models/{run}_rank_{rank}.h5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min', save_freq=250)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7873746a-cf7f-424c-beb7-c3989f8e3c38",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff6a30-b815-4812-8e8e-8c1e0b48e2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 00:11:34.194212: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-05-01 00:11:34.343025: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: loss improved from inf to 0.10466, saving model to ./models/9_rank_True.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chandler/anaconda3/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: loss improved from 0.10466 to 0.06470, saving model to ./models/9_rank_True.h5\n",
      "625/625 - 12s - loss: 0.0550 - mean_squared_error: 0.0550 - val_loss: 0.0114 - val_mean_squared_error: 0.0114 - 12s/epoch - 19ms/step\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 00002: loss improved from 0.06470 to 0.01479, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00002: loss improved from 0.01479 to 0.01395, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00002: loss improved from 0.01395 to 0.01342, saving model to ./models/9_rank_True.h5\n",
      "625/625 - 9s - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0115 - val_mean_squared_error: 0.0115 - 9s/epoch - 14ms/step\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 00003: loss improved from 0.01342 to 0.01173, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00003: loss improved from 0.01173 to 0.01152, saving model to ./models/9_rank_True.h5\n",
      "625/625 - 9s - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0099 - val_mean_squared_error: 0.0099 - 9s/epoch - 15ms/step\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 00004: loss improved from 0.01152 to 0.01075, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00004: loss improved from 0.01075 to 0.01040, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00004: loss improved from 0.01040 to 0.01018, saving model to ./models/9_rank_True.h5\n",
      "625/625 - 9s - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0096 - val_mean_squared_error: 0.0096 - 9s/epoch - 14ms/step\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 00005: loss improved from 0.01018 to 0.00961, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00005: loss improved from 0.00961 to 0.00945, saving model to ./models/9_rank_True.h5\n",
      "625/625 - 9s - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0088 - val_mean_squared_error: 0.0088 - 9s/epoch - 14ms/step\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 00006: loss improved from 0.00945 to 0.00911, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00006: loss improved from 0.00911 to 0.00896, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00006: loss improved from 0.00896 to 0.00890, saving model to ./models/9_rank_True.h5\n",
      "625/625 - 9s - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - 9s/epoch - 15ms/step\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 00007: loss improved from 0.00890 to 0.00858, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00858\n",
      "625/625 - 9s - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - 9s/epoch - 14ms/step\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 00008: loss improved from 0.00858 to 0.00824, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00008: loss improved from 0.00824 to 0.00814, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00814\n",
      "625/625 - 9s - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - 9s/epoch - 14ms/step\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 00009: loss improved from 0.00814 to 0.00793, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00793\n",
      "625/625 - 9s - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0072 - val_mean_squared_error: 0.0072 - 9s/epoch - 14ms/step\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 00010: loss improved from 0.00793 to 0.00727, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00727\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00727\n",
      "625/625 - 9s - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0072 - val_mean_squared_error: 0.0072 - 9s/epoch - 14ms/step\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00727\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00727\n",
      "625/625 - 9s - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0067 - val_mean_squared_error: 0.0067 - 9s/epoch - 14ms/step\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 00012: loss improved from 0.00727 to 0.00726, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00012: loss improved from 0.00726 to 0.00724, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00724\n",
      "625/625 - 9s - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0085 - val_mean_squared_error: 0.0085 - 9s/epoch - 15ms/step\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 00013: loss improved from 0.00724 to 0.00697, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00697\n",
      "625/625 - 9s - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0069 - val_mean_squared_error: 0.0069 - 9s/epoch - 15ms/step\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00697\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00697\n",
      "\n",
      "Epoch 00014: loss improved from 0.00697 to 0.00696, saving model to ./models/9_rank_True.h5\n",
      "625/625 - 9s - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0073 - val_mean_squared_error: 0.0073 - 9s/epoch - 15ms/step\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 00015: loss improved from 0.00696 to 0.00684, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00015: loss improved from 0.00684 to 0.00667, saving model to ./models/9_rank_True.h5\n",
      "625/625 - 9s - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0064 - val_mean_squared_error: 0.0064 - 9s/epoch - 15ms/step\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00667\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00667\n",
      "\n",
      "Epoch 00016: loss improved from 0.00667 to 0.00666, saving model to ./models/9_rank_True.h5\n",
      "625/625 - 9s - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0064 - val_mean_squared_error: 0.0064 - 9s/epoch - 14ms/step\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 00017: loss improved from 0.00666 to 0.00654, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00654\n",
      "625/625 - 9s - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0064 - val_mean_squared_error: 0.0064 - 9s/epoch - 14ms/step\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 00018: loss improved from 0.00654 to 0.00633, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00633\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00633\n",
      "625/625 - 9s - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0063 - val_mean_squared_error: 0.0063 - 9s/epoch - 14ms/step\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00633\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00633\n",
      "625/625 - 9s - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0063 - val_mean_squared_error: 0.0063 - 9s/epoch - 14ms/step\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00633\n",
      "\n",
      "Epoch 00020: loss improved from 0.00633 to 0.00624, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00624\n",
      "625/625 - 9s - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - 9s/epoch - 14ms/step\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 00021: loss improved from 0.00624 to 0.00614, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00021: loss improved from 0.00614 to 0.00612, saving model to ./models/9_rank_True.h5\n",
      "625/625 - 9s - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0067 - val_mean_squared_error: 0.0067 - 9s/epoch - 15ms/step\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00612\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00612\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00612\n",
      "625/625 - 10s - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0061 - val_mean_squared_error: 0.0061 - 10s/epoch - 15ms/step\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 00023: loss improved from 0.00612 to 0.00603, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00603\n",
      "625/625 - 9s - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0064 - val_mean_squared_error: 0.0064 - 9s/epoch - 14ms/step\n",
      "Epoch 24/1000\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00603\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00603\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00603\n",
      "625/625 - 9s - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - 9s/epoch - 14ms/step\n",
      "Epoch 25/1000\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00603\n",
      "\n",
      "Epoch 00025: loss improved from 0.00603 to 0.00598, saving model to ./models/9_rank_True.h5\n",
      "625/625 - 9s - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - 9s/epoch - 15ms/step\n",
      "Epoch 26/1000\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00598\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00598\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00598\n",
      "625/625 - 9s - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - 9s/epoch - 15ms/step\n",
      "Epoch 27/1000\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00598\n",
      "\n",
      "Epoch 00027: loss improved from 0.00598 to 0.00597, saving model to ./models/9_rank_True.h5\n",
      "625/625 - 9s - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - 9s/epoch - 15ms/step\n",
      "Epoch 28/1000\n",
      "\n",
      "Epoch 00028: loss improved from 0.00597 to 0.00595, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00028: loss improved from 0.00595 to 0.00594, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00028: loss improved from 0.00594 to 0.00588, saving model to ./models/9_rank_True.h5\n",
      "625/625 - 9s - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - 9s/epoch - 15ms/step\n",
      "Epoch 29/1000\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00588\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00588\n",
      "625/625 - 9s - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - 9s/epoch - 15ms/step\n",
      "Epoch 30/1000\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00588\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00588\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00588\n",
      "625/625 - 9s - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - 9s/epoch - 14ms/step\n",
      "Epoch 31/1000\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00588\n",
      "\n",
      "Epoch 00031: loss improved from 0.00588 to 0.00586, saving model to ./models/9_rank_True.h5\n",
      "625/625 - 9s - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - 9s/epoch - 14ms/step\n",
      "Epoch 32/1000\n",
      "\n",
      "Epoch 00032: loss improved from 0.00586 to 0.00583, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00032: loss improved from 0.00583 to 0.00577, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00577\n",
      "625/625 - 9s - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - 9s/epoch - 15ms/step\n",
      "Epoch 33/1000\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00577\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00577\n",
      "625/625 - 9s - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - 9s/epoch - 15ms/step\n",
      "Epoch 34/1000\n",
      "\n",
      "Epoch 00034: loss improved from 0.00577 to 0.00572, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00572\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00572\n",
      "625/625 - 10s - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - 10s/epoch - 16ms/step\n",
      "Epoch 35/1000\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00572\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00572\n",
      "625/625 - 9s - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - 9s/epoch - 15ms/step\n",
      "Epoch 36/1000\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00572\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00572\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00572\n",
      "625/625 - 9s - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - 9s/epoch - 15ms/step\n",
      "Epoch 37/1000\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00572\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00572\n",
      "625/625 - 9s - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - 9s/epoch - 14ms/step\n",
      "Epoch 38/1000\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00572\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00572\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00572\n",
      "625/625 - 9s - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - 9s/epoch - 15ms/step\n",
      "Epoch 39/1000\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00572\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00572\n",
      "625/625 - 9s - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - 9s/epoch - 14ms/step\n",
      "Epoch 40/1000\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00572\n",
      "\n",
      "Epoch 00040: loss improved from 0.00572 to 0.00568, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00568\n",
      "625/625 - 9s - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - 9s/epoch - 14ms/step\n",
      "Epoch 41/1000\n",
      "\n",
      "Epoch 00041: loss improved from 0.00568 to 0.00567, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00567\n",
      "625/625 - 9s - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - 9s/epoch - 14ms/step\n",
      "Epoch 42/1000\n",
      "\n",
      "Epoch 00042: loss improved from 0.00567 to 0.00549, saving model to ./models/9_rank_True.h5\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00549\n",
      "625/625 - 9s - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - 9s/epoch - 14ms/step\n",
      "Epoch 43/1000\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00549\n",
      "625/625 - 9s - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - 9s/epoch - 14ms/step\n",
      "Epoch 44/1000\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00549\n",
      "625/625 - 9s - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - 9s/epoch - 15ms/step\n",
      "Epoch 45/1000\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00549\n",
      "625/625 - 9s - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - 9s/epoch - 14ms/step\n",
      "Epoch 46/1000\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00549\n",
      "625/625 - 9s - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - 9s/epoch - 14ms/step\n",
      "Epoch 47/1000\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00549\n",
      "625/625 - 9s - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - 9s/epoch - 15ms/step\n",
      "Epoch 48/1000\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00549\n",
      "625/625 - 9s - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - 9s/epoch - 15ms/step\n",
      "Epoch 49/1000\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00549\n",
      "625/625 - 9s - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0057 - val_mean_squared_error: 0.0057 - 9s/epoch - 15ms/step\n",
      "Epoch 50/1000\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00549\n",
      "625/625 - 9s - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - 9s/epoch - 15ms/step\n",
      "Epoch 51/1000\n",
      "\n",
      "Epoch 00051: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00051: loss did not improve from 0.00549\n",
      "625/625 - 9s - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - 9s/epoch - 15ms/step\n",
      "Epoch 52/1000\n",
      "\n",
      "Epoch 00052: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00052: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00052: loss did not improve from 0.00549\n",
      "625/625 - 9s - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - 9s/epoch - 14ms/step\n",
      "Epoch 53/1000\n",
      "\n",
      "Epoch 00053: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 00053: loss did not improve from 0.00549\n",
      "625/625 - 9s - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0055 - val_mean_squared_error: 0.0055 - 9s/epoch - 14ms/step\n",
      "Epoch 54/1000\n",
      "\n",
      "Epoch 00054: loss did not improve from 0.00549\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    recipes, quant, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs, \n",
    "    validation_split = validation_split, \n",
    "    verbose=verbose,\n",
    "    callbacks = callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7789f-4209-4755-b948-bfbf9d1db5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "# summarize history for accuracy\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('Progress')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training','Validation'],loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6effc8be-cb0a-4dad-98c4-0b15110d33cd",
   "metadata": {},
   "source": [
    "## Accuracy Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36cad68-e49a-4090-a978-777356696905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy formula:\n",
    "#   measured values < 1 are set to 1\n",
    "#   error = 100(( |Measured Value - Given Value| ) / max(Measured Value, Given Value))\n",
    "#   accuracy = 100 - error\n",
    "def accuracy(pred, actual):\n",
    "    \n",
    "    macro_index = [0,1,5,8]\n",
    "    micro_index = [2,3,4,6,7,8,10,11,12,13,14]\n",
    "    \n",
    "    accs = {}\n",
    "    totals = []\n",
    "    \n",
    "    for i in range(pred.shape[0]): # for each recipe\n",
    "        recipe_accs = np.zeros((pred.shape[1])) # last element for accuracy across all ingrs\n",
    "        recipe_tot = {}\n",
    "        \n",
    "        for j in range(pred.shape[1]): # for each ingredient\n",
    "            measured_ingr = pred[i,j]\n",
    "            given_ingr = actual[i,j]\n",
    "            \n",
    "            if given_ingr < 1:\n",
    "                given_ingr = 1 # avoid divide by 0 error\n",
    "            if measured_ingr < 1:\n",
    "                measured_ingr = 1\n",
    "            \n",
    "            \n",
    "            error = 100 * abs(measured_ingr - given_ingr)/max(given_ingr,measured_ingr)\n",
    "            accuracy = round(abs(100 - error),2)\n",
    "            \n",
    "            \n",
    "            if (accuracy < 0):\n",
    "                accuracy = 0\n",
    "            \n",
    "            recipe_accs[j] = accuracy\n",
    "        \n",
    "        accs[f\"{i}_mape\"] = round((np.sum(recipe_accs) / recipe_accs.shape[0]),2)\n",
    "        accs[f\"{i}_ingrs\"] = recipe_accs\n",
    "        \n",
    "\n",
    "        \n",
    "    return accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706eb789-c3cf-48c3-9dae-93e6d302bcba",
   "metadata": {},
   "source": [
    "## Testing Fake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134acc20-4c84-4128-ac45-d82aef19ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = Generator('nutrients.csv')\n",
    "test_gen.generate(test_examples) # generates arg number of examples\n",
    "\n",
    "if rank:\n",
    "    test_gen.rank()\n",
    "    \n",
    "test_recipes = test_gen.recipes\n",
    "test_quant = test_gen.quant\n",
    "    \n",
    "if normalize:\n",
    "    test_recipes = recipe_normalizer.normalize(test_recipes)\n",
    "    test_quant = quant_normalizer.normalize(test_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ce6aa-4acb-4abc-bdd5-0e3c80b56736",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_recipes)\n",
    "if normalize:\n",
    "    pred = quant_normalizer.inv_normalize(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3caa32-d5a3-4822-a35b-712f59c647a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = test_gen.quant"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f83510e7-3032-4f5f-94dd-6a4583f722c2",
   "metadata": {},
   "source": [
    "index = 5\n",
    "for i in range(len(pred[0])):\n",
    "    pred_num = str(round(pred[index,i],3))\n",
    "    act_num = str(round(actual[index,i],3))\n",
    "    \n",
    "    print(f\"pred: {pred_num} | actual: {act_num}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e217d273-dda1-4af0-acc2-1f5a0cf87e09",
   "metadata": {},
   "source": [
    "## Testing Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8954e7b9-da87-448e-9ae6-d7ef5c0a3f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_quant = \"./Recipe Data.csv\"\n",
    "ingr_nutr = \"./nutrients.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13fd588-802e-46cf-8435-e40b137d7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "realdata = RealData(recipe_quant,ingr_nutr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db691a7-0cc2-4b97-9909-41402cc33ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank:\n",
    "    realdata.rank()\n",
    "\n",
    "real_recipes = realdata.recipes\n",
    "real_quant = realdata.quant\n",
    "    \n",
    "if normalize:\n",
    "    real_recipes = recipe_normalizer.normalize(real_recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c342352-1581-4769-8105-7f55dfdb08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(real_recipes)\n",
    "if normalize:\n",
    "    pred = quant_normalizer.inv_normalize(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99980b4a-b68f-4a9f-b9ae-e22d67d0b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = realdata.quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859583a5-6d5d-423f-9eff-cb4afe25ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 6\n",
    "for i in range(len(pred[0])):\n",
    "    pred_num = str(round(pred[index,i],3))\n",
    "    act_num = str(round(actual[index,i],3))\n",
    "    \n",
    "    print(f\"pred: {pred_num} | actual: {act_num}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75fc47-e7c2-4464-a293-83941f499c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress = True)\n",
    "accs = accuracy(pred,actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c482c-6760-4e84-a8d1-ec0df8b183a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(model,recipe_normalizer,quant_normalizer, accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
